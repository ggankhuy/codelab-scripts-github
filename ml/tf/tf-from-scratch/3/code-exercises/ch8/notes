RNN CELL:

t[h] = Whh * t[h-1] + b[hh] -> 
output of hidden state/transformer hidden state = 
weight of hidden layer * prev hidden state + bias of hidden layer. 

t[x] = Wih * x[t] + b[ih] ->
output of input layer/transformed input state = 
weigth of input layer * input data + bias of input layer.

h[t] = tanh ( t[x] + t[h] ) ->
output of current iteration/updated hidden state = 
activation layer ( hidden state output + input layer output)

5.11.2024
decided to skip bidir rnn completion. may visit later.
deciding to skip gru cell p149


sbs_rnn=StepByStep(model, loss, optimizer)
sbs_rnn.set_loaders(train_loader, test_loader)
sbs_rnn.train(100)


